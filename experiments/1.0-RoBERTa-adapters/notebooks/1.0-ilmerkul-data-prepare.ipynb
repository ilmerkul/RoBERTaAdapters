{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config=\"../config\"\n",
    "path_save_raw_dataset = \"../data/dataset/raw\"\n",
    "path_save_process_dataset = \"../data/dataset/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:\n",
      "  ner_lin_size: 256\n",
      "  count_tags: 10\n",
      "  dropout: 0.2\n",
      "  hidden_size_adapter: 32\n",
      "processing:\n",
      "  data:\n",
      "    max_length: 512\n",
      "train:\n",
      "  epoch: 8\n",
      "  batch_sizes:\n",
      "  - 32\n",
      "  - 64\n",
      "  - 128\n",
      "  - 256\n",
      "  batch_milestones:\n",
      "  - 2\n",
      "  - 4\n",
      "  - 7\n",
      "  lr_0: 0.001\n",
      "  lr_milestones:\n",
      "  - 2\n",
      "  - 4\n",
      "  - 7\n",
      "  gamma: 0.464159\n",
      "  epoch_emb_requires_grad: 4\n",
      "  print_step: 100\n",
      "name: 1.0-RoBERTa-adapters\n",
      "mlflow_server: http://127.0.0.1:5000\n",
      "seed: 42\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pynex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\hydra\\_internal\\defaults_list.py:251: UserWarning: In 'experiment': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "initialize(version_base=None, config_path=path_config)\n",
    "cfg = compose(config_name=\"experiment\")\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe0fd5e290d4951b51524daadd3c048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477c203f02604d46aa472d1e395b7737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b02cd82f2a34933ab3b4f3211e8bbce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"eriktks/conll2003\", trust_remote_code=True)\n",
    "dataset.save_to_disk(path_save_raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\", truncation=True, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = cfg.processing.data.max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(batch):\n",
    "  tokens = list(map(lambda x: \" \".join(x), batch[\"tokens\"]))\n",
    "  d = tokenizer(tokens,\n",
    "                   truncation=True,\n",
    "                   padding='max_length',\n",
    "                   return_token_type_ids=True,\n",
    "                   max_length=MAX_LENGTH)\n",
    "  d[\"len\"] = list(map(len, batch[\"ner_tags\"]))\n",
    "  d[\"ner_tags\"] = list(map(lambda x: list(map(lambda y: y+1, x)), batch[\"ner_tags\"]))\n",
    "  d[\"ner_tags\"] = [x[:MAX_LENGTH] if len(x) > MAX_LENGTH else x + [0] * (MAX_LENGTH - len(x)) for x in batch[\"ner_tags\"]]\n",
    "  return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(tokenize_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns([\"id\", \"tokens\", \"chunk_tags\", \"pos_tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'len'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'len'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'len'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"ner_tags\", \"input_ids\", \"attention_mask\", \"token_type_ids\", \"len\"]\n",
    "\n",
    "dataset.set_format(\"torch\", columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df491667077464397341a96c9181988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1cd9079235420ab7380857a55861a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9043d7f9f6804fe686278490a1892760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk(path_save_process_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
